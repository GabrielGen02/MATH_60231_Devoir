{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628c1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "pgpass file created at C:\\Users\\Gabri\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# connexion a wrds \n",
    "import wrds\n",
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "754c497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Connexion WRDS...\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "pgpass file created at C:\\Users\\Gabri\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n",
      ">>> Connexion WRDS OK.\n",
      "\n",
      ">>> 13488 tickers ont au moins un EPS disponible.\n",
      ">>> Échantillon final : 50 tickers sélectionnés.\n",
      ">>> Prix téléchargés.\n",
      "\n",
      ">>> EPS téléchargés.\n",
      "\n",
      ">>> Jointure CRSP + EPS effectuée.\n",
      "\n",
      ">>> Trailing EPS & P/E calculés.\n",
      "\n",
      "              date    prc  permno ticker   gvkey    datadate  epspxq  eps_ttm  \\\n",
      "2298858 2021-06-30  26.06   11628   CPBI  043152  2021-06-30    <NA>      NaN   \n",
      "2298875 2021-07-01  26.17   11628   CPBI  043152  2021-06-30    <NA>      NaN   \n",
      "2298892 2021-07-02  25.81   11628   CPBI  043152  2021-06-30    <NA>      NaN   \n",
      "2298909 2021-07-06  25.29   11628   CPBI  043152  2021-06-30    <NA>      NaN   \n",
      "2298926 2021-07-07  24.85   11628   CPBI  043152  2021-06-30    <NA>      NaN   \n",
      "\n",
      "         trailing_pe  \n",
      "2298858         <NA>  \n",
      "2298875         <NA>  \n",
      "2298892         <NA>  \n",
      "2298909         <NA>  \n",
      "2298926         <NA>  \n",
      ">>> Pipeline terminé, CSV sauvegardé.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import wrds\n",
    "import pandas as pd\n",
    "import numpy as np  # pour np.random.choice\n",
    "\n",
    "np.random.seed(42)  # pour reproductibilité\n",
    "\n",
    "# --- 1️⃣ Connexion WRDS ---\n",
    "def connect_wrds():\n",
    "    print(\">>> Connexion WRDS...\")\n",
    "    db = wrds.Connection()\n",
    "    print(\">>> Connexion WRDS OK.\\n\")\n",
    "    return db\n",
    "\n",
    "# --- 2️⃣ Échantillon aléatoire de 50 entreprises S&P500 ---\n",
    "def get_sp500_sample(df, db):\n",
    "    \"\"\"\n",
    "    Retourne un échantillon de 50 tickers du S&P500 avec EPS disponibles.\n",
    "    df : dataframe initial CRSP (permno + ticker)\n",
    "    db : connexion WRDS\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    np.random.seed(42)  # reproductibilité\n",
    "\n",
    "    # Tickres uniques\n",
    "    unique_tickers = df[\"ticker\"].dropna().unique()\n",
    "\n",
    "    # Vérifier quels tickers ont des données EPS\n",
    "    valid_tickers = []\n",
    "    for ticker in unique_tickers:\n",
    "        query = f\"\"\"\n",
    "            SELECT 1\n",
    "            FROM comp.fundq\n",
    "            WHERE tic = '{ticker}'\n",
    "            LIMIT 1\n",
    "        \"\"\"\n",
    "        result = db.raw_sql(query)\n",
    "        if not result.empty:\n",
    "            valid_tickers.append(ticker)\n",
    "\n",
    "    print(f\">>> {len(valid_tickers)} tickers ont au moins un EPS disponible.\")\n",
    "\n",
    "    # Échantillon aléatoire de 50 tickers\n",
    "    if len(valid_tickers) < 50:\n",
    "        print(\"Attention : moins de 50 tickers avec EPS, on prend tout ce qui est disponible.\")\n",
    "        sample_tickers = valid_tickers\n",
    "    else:\n",
    "        sample_tickers = np.random.choice(valid_tickers, size=50, replace=False)\n",
    "\n",
    "    # Construire le dataframe final (ticker + permno)\n",
    "    sample = df[df[\"ticker\"].isin(sample_tickers)][[\"permno\", \"ticker\"]].drop_duplicates()\n",
    "\n",
    "    print(f\">>> Échantillon final : {len(sample['ticker'].unique())} tickers sélectionnés.\")\n",
    "    return sample\n",
    "\n",
    "\n",
    "# --- 3️⃣ Extraction des prix CRSP ---\n",
    "def get_prices(db, sample):\n",
    "    permno_list = \"', '\".join(sample['permno'].astype(str).unique())\n",
    "    query = f\"\"\"\n",
    "        SELECT date, prc, permno\n",
    "        FROM crsp.dsf\n",
    "        WHERE permno IN ('{permno_list}')\n",
    "        ORDER BY permno, date\n",
    "    \"\"\"\n",
    "    prices = db.raw_sql(query)\n",
    "    print(\">>> Prix téléchargés.\\n\")\n",
    "    return prices\n",
    "\n",
    "# --- 4️⃣ Extraction des EPS Compustat ---\n",
    "def get_eps(db, sample):\n",
    "    tic_list = \"', '\".join(sample['ticker'].unique())\n",
    "    query = f\"\"\"\n",
    "        SELECT gvkey, tic AS ticker, datadate, epspxq\n",
    "        FROM comp.fundq\n",
    "        WHERE tic IN ('{tic_list}')\n",
    "        ORDER BY gvkey, datadate\n",
    "    \"\"\"\n",
    "    eps = db.raw_sql(query)\n",
    "    print(\">>> EPS téléchargés.\\n\")\n",
    "    return eps\n",
    "\n",
    "# --- 5️⃣ Jointure CRSP ↔ EPS via ticker ---\n",
    "def merge_prices_eps(prices, eps, sample):\n",
    "    merged = prices.merge(sample, on='permno', how='left')\n",
    "    merged = merged.merge(eps, on='ticker', how='left')\n",
    "    \n",
    "    # Filtrer EPS publié avant la date du prix\n",
    "    merged = merged[merged['datadate'] <= merged['date']]\n",
    "    print(\">>> Jointure CRSP + EPS effectuée.\\n\")\n",
    "    return merged\n",
    "\n",
    "# --- 6️⃣ Calcul Trailing P/E ---\n",
    "def compute_trailing_PE(merged):\n",
    "    merged = merged.sort_values(['permno', 'date'])\n",
    "    merged['eps_ttm'] = merged.groupby('permno')['epspxq'].rolling(4).sum().reset_index(level=0, drop=True)\n",
    "    merged['eps_ttm'] = merged.groupby('permno')['eps_ttm'].ffill()\n",
    "    merged['trailing_pe'] = merged['prc'] / merged['eps_ttm']\n",
    "    print(\">>> Trailing EPS & P/E calculés.\\n\")\n",
    "    return merged\n",
    "\n",
    "# --- 7️⃣ Pipeline complet ---\n",
    "def run_pipeline():\n",
    "    db = connect_wrds()\n",
    "\n",
    "    # Charger la liste S&P500 depuis CRSP\n",
    "    df = db.raw_sql(\"\"\"\n",
    "        SELECT permno, ticker\n",
    "        FROM crsp.msenames\n",
    "        WHERE shrcd IN (10,11)\n",
    "        AND exchcd IN (1,2,3)\n",
    "    \"\"\")\n",
    "\n",
    "    sample = get_sp500_sample(df, db)\n",
    "    prices = get_prices(db, sample)\n",
    "    eps = get_eps(db, sample)\n",
    "\n",
    "    merged = merge_prices_eps(prices, eps, sample)\n",
    "    final = compute_trailing_PE(merged)\n",
    "    \n",
    "    # Filtrer pour les dates après 2003\n",
    "    final['date'] = pd.to_datetime(final['date'])\n",
    "    final = final[final['date'] > \"2003-01-01\"]\n",
    "\n",
    "    print(final.head())\n",
    "    return final\n",
    "\n",
    "# --- 8️⃣ Exécution ---\n",
    "if __name__ == \"__main__\":\n",
    "    final_df = run_pipeline()\n",
    "    final_df.to_csv(\"SP500_trailing_PE.csv\", index=False)\n",
    "    print(\">>> Pipeline terminé, CSV sauvegardé.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "670dde81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de NaN par ticker :\n",
      "         EPS_MOBILE  EPS  Prix_bene  prix\n",
      "ticker                                  \n",
      "ASHW             0  0.0        0.0   0.0\n",
      "BMTC             0  0.0        0.0   0.0\n",
      "COSN             0  0.0        0.0   0.0\n",
      "CPBI             0  0.0        0.0   0.0\n",
      "CRRC             0  0.0        0.0   0.0\n",
      "CRZY             0  0.0        0.0   0.0\n",
      "FACE             0  0.0        0.0   0.0\n",
      "FAT              0  0.0        0.0   0.0\n",
      "HOOK             0  0.0        0.0   0.0\n",
      "HOTJ             0  0.0        0.0   0.0\n",
      "IRM              0  0.0        0.0   0.0\n",
      "MEJ              0  0.0        0.0   0.0\n",
      "MMCE             0  0.0        0.0   0.0\n",
      "MNTS             0  0.0        0.0   0.0\n",
      "PPBI             0  0.0        0.0   0.0\n",
      "QEPC             0  0.0        0.0   0.0\n",
      "SF               0  0.0        0.0   0.0\n",
      "SIBN             0  0.0        0.0   0.0\n",
      "STC              0  0.0        0.0   0.0\n",
      "VHS              0  0.0        0.0   0.0\n",
      "WD               0  0.0        0.0   0.0\n",
      "XPO              0  0.0        0.0   0.0\n",
      "Date minimale : 2003-01-02 00:00:00\n",
      "Date maximale : 2024-12-31 00:00:00\n",
      "type de données\n",
      "date          datetime64[ns]\n",
      "prix                 Float64\n",
      "permno                 Int64\n",
      "ticker        string[python]\n",
      "gvkey         string[python]\n",
      "datadate      string[python]\n",
      "EPS                  Float64\n",
      "EPS_MOBILE           float64\n",
      "Prix_bene            Float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prix</th>\n",
       "      <th>permno</th>\n",
       "      <th>ticker</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th>EPS</th>\n",
       "      <th>EPS_MOBILE</th>\n",
       "      <th>Prix_bene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12806727</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>6.9</td>\n",
       "      <td>76322</td>\n",
       "      <td>ASHW</td>\n",
       "      <td>021519</td>\n",
       "      <td>1988-01-31</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-62.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806728</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>6.9</td>\n",
       "      <td>76322</td>\n",
       "      <td>ASHW</td>\n",
       "      <td>021519</td>\n",
       "      <td>1988-04-30</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-62.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806729</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>6.9</td>\n",
       "      <td>76322</td>\n",
       "      <td>ASHW</td>\n",
       "      <td>021519</td>\n",
       "      <td>1988-07-31</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-62.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806730</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>6.9</td>\n",
       "      <td>76322</td>\n",
       "      <td>ASHW</td>\n",
       "      <td>021519</td>\n",
       "      <td>1988-10-31</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-62.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806731</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>6.9</td>\n",
       "      <td>76322</td>\n",
       "      <td>ASHW</td>\n",
       "      <td>021519</td>\n",
       "      <td>1989-01-31</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-57.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  prix  permno ticker   gvkey    datadate   EPS  \\\n",
       "12806727 2003-01-02   6.9   76322   ASHW  021519  1988-01-31 -0.01   \n",
       "12806728 2003-01-02   6.9   76322   ASHW  021519  1988-04-30 -0.07   \n",
       "12806729 2003-01-02   6.9   76322   ASHW  021519  1988-07-31 -0.02   \n",
       "12806730 2003-01-02   6.9   76322   ASHW  021519  1988-10-31 -0.01   \n",
       "12806731 2003-01-02   6.9   76322   ASHW  021519  1989-01-31 -0.02   \n",
       "\n",
       "          EPS_MOBILE  Prix_bene  \n",
       "12806727       -0.11 -62.727273  \n",
       "12806728       -0.11 -62.727273  \n",
       "12806729       -0.11 -62.727273  \n",
       "12806730       -0.11 -62.727273  \n",
       "12806731       -0.12      -57.5  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nettoyage du df \n",
    "def nettoyage_df(df):\n",
    "    # Renommer les colonnes proprement\n",
    "    df = df.rename(columns={\n",
    "        \"prc\": \"prix\",\n",
    "        \"epspxq\": \"EPS\",\n",
    "        \"eps_ttm\": \"EPS_MOBILE\",\n",
    "        \"trailing_pe\": \"Prix_bene\"\n",
    "    })\n",
    "    \n",
    "    # Trier les données par entreprise et par date\n",
    "    df = df.sort_values(['permno', 'date'])\n",
    "\n",
    "    # Supprimer une ou plusieurs colonnes\n",
    "    df = df.drop(columns=['EPS_MOBILE', 'Prix_bene'])\n",
    "    \n",
    "    # Remplir tous les NaN dans EPS avec ffill + bfill\n",
    "    df['EPS'] = df.groupby('permno')['EPS'].transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "    # calcule de ESP mobile sans NaN \n",
    "    df['EPS_MOBILE'] = df.groupby('permno')['EPS'].rolling(4).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "    # Remplir tous les NaN dans EPS_mobile avec ffill + bfill\n",
    "    df['EPS_MOBILE'] = df.groupby('permno')['EPS_MOBILE'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    # calcule du ratio p/b sans NaN \n",
    "    df['Prix_bene'] = df['prix'] / df['EPS_MOBILE']\n",
    "\n",
    "    # Supprimer toutes les lignes où EPS_MOBILE ou Prix_bene est NaN\n",
    "    df = df.dropna(subset=['EPS_MOBILE', 'Prix_bene'])\n",
    "\n",
    "    # Calculer le nombre de NaN par colonne (inspection)\n",
    "    nan_summary = df.groupby(\"ticker\").agg({\n",
    "        \"EPS_MOBILE\": lambda x: x.isna().sum(),\n",
    "        \"EPS\": lambda x: x.isna().sum(),\n",
    "        \"Prix_bene\": lambda x: x.isna().sum(),\n",
    "        \"prix\": lambda x: x.isna().sum()\n",
    "    })\n",
    "    print(\"Nombre de NaN par ticker :\\n\", nan_summary)\n",
    "    \n",
    "    # Calcul du pourcentage de NaN pour EPS\n",
    "    nan_eps_pct = df.groupby('ticker')['EPS'].apply(lambda x: x.isna().mean())\n",
    "    \n",
    "    # Garder uniquement les tickers avec moins de 30 % de NaN sur EPS\n",
    "    tickers_valides = nan_eps_pct[nan_eps_pct <= 0.30].index\n",
    "    df = df[df['ticker'].isin(tickers_valides)]\n",
    "    \n",
    "    # Filtrage des dates (> 2003)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df[df['date'] > \"2003-01-01\"]\n",
    "    \n",
    "    # Dates min/max pour vérification\n",
    "    print(\"Date minimale :\", df['date'].min())\n",
    "    print(\"Date maximale :\", df['date'].max())\n",
    "\n",
    "    # Convertir en float\n",
    "    float_cols = ['prix', 'EPS', 'EPS_MOBILE', 'Prix_bene']\n",
    "    for col in float_cols:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    \n",
    "    # Convertir la date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Vérifier le résultat\n",
    "    print(\"type de données\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # trie par date et ticker \n",
    "    df = df.sort_values(['ticker', 'date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# résultat \n",
    "df = nettoyage_df(final_df)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
