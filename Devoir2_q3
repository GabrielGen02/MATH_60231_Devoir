import pandas as pd
import numpy as np

# 1) Load the panel we created
df = pd.read_csv("PE_SP500_50.csv", parse_dates=["Date"])

# Make names a bit easier to work with
df = df.rename(columns={"Date": "date",
                        "Price": "price",
                        "EPS": "eps",
                        "PE": "pe"})

print(df.head())
print(df.columns)

import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV
from sklearn.metrics import mean_squared_error
from scipy import stats

# ---------- 1) Load data ----------
df = pd.read_csv("PE_SP500_50.csv", parse_dates=["Date"])
df = df.rename(columns={"Date": "date",
                        "Price": "price",
                        "EPS": "eps",
                        "PE": "pe"})

# sort by firm and time
df = df.sort_values(["Ticker", "date"]).reset_index(drop=True)

# target = next-period price for each stock
df["price_next"] = df.groupby("Ticker")["price"].shift(-1)

# baseline regressor: EPS_expected × trailing P/E
# here we use eps as proxy for expected EPS
df["x_base"] = df["eps"] * df["pe"]   # this equals current price, but that's ok:
                                      # we are predicting next month's price.

# ---------- 2) Create additional predictors (Q3a) ----------

# lags of price, eps, pe
df["price_lag1"] = df.groupby("Ticker")["price"].shift(1)
df["price_lag2"] = df.groupby("Ticker")["price"].shift(2)
df["eps_lag1"]   = df.groupby("Ticker")["eps"].shift(1)
df["pe_lag1"]    = df.groupby("Ticker")["pe"].shift(1)

# simple return and short-run volatility
df["ret_1"] = df.groupby("Ticker")["price"].pct_change()

df["vol_6"] = (
    df.groupby("Ticker")["price"]
      .rolling(window=6, min_periods=3)
      .std()
      .reset_index(level=0, drop=True)
)

# non-linear terms and interaction
df["eps_sq"] = df["eps"] ** 2
df["pe_sq"]  = df["pe"] ** 2
df["eps_pe_interact"] = df["eps"] * df["pe"]

# drop rows without enough history
df = df.dropna().reset_index(drop=True)

# define y and X
y = df["price_next"]

feature_cols = [
    "x_base",                 # baseline variable
    "price", "price_lag1", "price_lag2",
    "eps", "eps_lag1",
    "pe", "pe_lag1",
    "ret_1", "vol_6",
    "eps_sq", "pe_sq",
    "eps_pe_interact"
]

X = df[feature_cols]

# ---------- 3) Train / test split (time-based) ----------
# sort by date overall then split 80% / 20%
df = df.sort_values(["date", "Ticker"]).reset_index(drop=True)
X = df[feature_cols]
y = df["price_next"]

split_idx = int(0.8 * len(df))
X_train, X_test = X.iloc[:split_idx, :], X.iloc[split_idx:, :]
y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# ---------- 4) Baseline model: OLS on x_base only ----------
lr_base = LinearRegression()
lr_base.fit(X_train[["x_base"]], y_train)
y_pred_base = lr_base.predict(X_test[["x_base"]])
rmse_base = rmse(y_test, y_pred_base)

# ---------- 5) Ridge / LASSO / Elastic Net (Q3b) ----------

# scale predictors for penalized regressions
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled  = scaler.transform(X_test)

alphas = np.logspace(-4, 4, 20)

# Ridge
ridge = RidgeCV(alphas=alphas, cv=5)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)
rmse_ridge = rmse(y_test, y_pred_ridge)

# LASSO
lasso = LassoCV(alphas=alphas, cv=5, max_iter=10000)
lasso.fit(X_train_scaled, y_train)
y_pred_lasso = lasso.predict(X_test_scaled)
rmse_lasso = rmse(y_test, y_pred_lasso)

# Elastic Net
enet = ElasticNetCV(alphas=alphas, l1_ratio=[0.2, 0.5, 0.8],
                    cv=5, max_iter=10000)
enet.fit(X_train_scaled, y_train)
y_pred_enet = enet.predict(X_test_scaled)
rmse_enet = rmse(y_test, y_pred_enet)

print("RMSE baseline (x_base):", rmse_base)
print("RMSE Ridge:", rmse_ridge)
print("RMSE LASSO:", rmse_lasso)
print("RMSE Elastic Net:", rmse_enet)

# choose best model by RMSE
rmse_dict = {
    "base": rmse_base,
    "ridge": rmse_ridge,
    "lasso": rmse_lasso,
    "enet": rmse_enet
}
print("\nBest model by RMSE:", min(rmse_dict, key=rmse_dict.get))

# suppose LASSO is best; if another is best, just change below
y_pred_best = y_pred_lasso

# ---------- 6) Diebold–Mariano test: best model vs baseline (Q3c) ----------

def diebold_mariano(e1, e2):
    """
    e1, e2: forecast errors (y - y_hat)
    h = 1 horizon, loss = squared error
    """
    d = (e1**2 - e2**2)
    d_mean = np.mean(d)
    d_var = np.var(d, ddof=1)
    T = len(d)

    dm_stat = d_mean / np.sqrt(d_var / T)
    p_value = 2 * stats.t.sf(np.abs(dm_stat), df=T-1)
    return dm_stat, p_value

e_base = y_test - y_pred_base
e_best = y_test - y_pred_best

dm_stat, p_val = diebold_mariano(e_best.values, e_base.values)

print("\nDiebold–Mariano statistic (best vs baseline):", dm_stat)
print("p-value:", p_val)
